{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentaion with masked facies\n",
    "\n",
    "Squish rectangular images to square\n",
    "\n",
    "Using mask images processed in 01_02_mask_processing\n",
    "\n",
    "550x550 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from numbers import Integral\n",
    "from random import uniform\n",
    "from PIL import Image as pil_image\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision import Image\n",
    "from fastai.vision.transform import _minus_epsilon\n",
    "from fastai.vision.data import SegmentationProcessor\n",
    "from fastai.vision.interpret import SegmentationInterpretation\n",
    "from fastai.callbacks.tracker import SaveModelCallback\n",
    "from mask_functions import *\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from IPython.display import display \n",
    "import datetime\n",
    "import uuid\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.60.dev0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID: 492f5ad9, DATE: 20191222\n"
     ]
    }
   ],
   "source": [
    "DATE = datetime.datetime.today().strftime('%Y%m%d')\n",
    "UID=str(uuid.uuid4())[:8]\n",
    "print(f'UID: {UID}, DATE: {DATE}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UID='37c69040'\n",
    "#DATE='20191217'\n",
    "NB='03_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFERENCE_MODEL='02_10_0-dfdf95a0_rn34_128-s2-r0-20191222'\n",
    "INFERENCE_MODEL='02_10_1-be4a9fe2_rn34_256-s2-r0-20191222'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_DATA=False\n",
    "SUBSET_LEN=171\n",
    "\n",
    "VAL_FILE='val_20pct_0.csv'\n",
    "\n",
    "TGT_HEIGHT_SMALL = 128\n",
    "TGT_HEIGHT_MEDIUM = 256\n",
    "TGT_HEIGHT_FULL = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data')\n",
    "train_images = data_dir/'train_images'\n",
    "train_path = train_images/'cropped_512/train'\n",
    "train_mask = train_path/'masks'\n",
    "train_img = train_path/'images'\n",
    "\n",
    "test_img = train_images/'cropped_512/test'\n",
    "\n",
    "preds_path = data_dir/'preds'\n",
    "preds_path.mkdir(exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = data_dir/'CAX_LogFacies_Train_File.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test = data_dir/'CAX_LogFacies_Test_File.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = array(['Background', 'Funnel', 'None', 'Cylindrical', 'Symmetrical', 'Bell'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>well_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>well_1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>well_2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>well_3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>well_4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  well_0.png\n",
       "1  well_1.png\n",
       "2  well_2.png\n",
       "3  well_3.png\n",
       "4  well_4.png"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv(filename)\n",
    "training_data.head()\n",
    "training_data['well_file']='well_'+training_data['well_id'].astype(str)+'.png'\n",
    "wells=training_data['well_file'].unique()\n",
    "all_wells_df=pd.DataFrame(wells)\n",
    "all_wells_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>well_id</th>\n",
       "      <th>GR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CAX_0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>113.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CAX_1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>120.896397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CAX_2</td>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "      <td>115.342793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CAX_3</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "      <td>118.859190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CAX_4</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "      <td>127.735587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id  row_id  well_id          GR\n",
       "0     CAX_0       0     5000  113.950000\n",
       "1     CAX_1       1     5000  120.896397\n",
       "2     CAX_2       2     5000  115.342793\n",
       "3     CAX_3       3     5000  118.859190\n",
       "4     CAX_4       4     5000  127.735587"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(file_test)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wd=1e-2\n",
    "#learn = unet_learner(data, models.resnet34, metrics=acc_camvid, wd=wd).to_fp16()\n",
    "#test_data = SegmentationItemList.from_folder(test_img)\n",
    "#learn=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "name2id = {v:k for k,v in enumerate(codes)}\n",
    "void_code = name2id['Background']\n",
    "print(void_code)\n",
    "\n",
    "def acc_bgvoid(input, target):\n",
    "    #print(f'in: {input.shape}, tgt: {target.shape}')\n",
    "    target = target.squeeze(1)\n",
    "    mask = target != void_code\n",
    "    return (input.argmax(dim=1)[mask]==target[mask]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/train_images/cropped_512/test')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = SegmentationItemList.from_folder(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path=train_img, file=f'{INFERENCE_MODEL}.pkl', test=test_data, tfm_y=False, dl_tfms=None)\n",
    "learn=learn.to_fp16()\n",
    "#learn.model = torch.nn.DataParallel(learn.model, device_ids=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={'padding_mode': 'reflection', 'row_pct': 0.5, 'col_pct': 0.5}, do_run=True, is_random=True, use_on_y=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.test_ds.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.data.test_ds.tfms=None\n",
    "#learn.data.train_ds.tfms=None\n",
    "#learn.data.valid_ds.tfms=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im = train_images/'cropped/mask_fill/test/cropped/well_5000_GR_crop_0.png'\n",
    "#img=pil_image.open(im)\n",
    "#prediction = learn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0477e+09)\n"
     ]
    }
   ],
   "source": [
    "# Predictions for test set\n",
    "preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n",
    "#preds = (preds[:,1,...]>best_thr).long().numpy()\n",
    "print(preds.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16000, 6, 256, 256])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 256, 256])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(preds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Background', 'Funnel', 'None', 'Cylindrical', 'Symmetrical', 'Bell'], dtype='<U11')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16000, 256, 256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first pass we want the mode (most common) class for each column in the image\n",
    "\n",
    "But we want to first ignore background\n",
    "\n",
    "Lets check a single prediction first\n",
    "\n",
    "Mult by 40 so can see different colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "npa=labels[0].numpy().astype(np.int32)*40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(npa[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pil_image.fromarray(npa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feeb33559d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16000, 256, 256])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code for calculating median of columns in numpy array but ignoring 0 (background)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "n=np.array([[0,2,1], [0,1,3], [1,2,3]])\n",
    "m_mask = n != 0  \n",
    "new_m = np.where(m_mask, n, np.nan)\n",
    "m=mode(new_m, axis=0)\n",
    "r=m[0]\n",
    "r=r[0].astype(int)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>well_id</th>\n",
       "      <th>GR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CAX_0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>113.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CAX_1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>120.896397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CAX_2</td>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "      <td>115.342793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CAX_3</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "      <td>118.859190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CAX_4</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "      <td>127.735587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id  row_id  well_id          GR\n",
       "0     CAX_0       0     5000  113.950000\n",
       "1     CAX_1       1     5000  120.896397\n",
       "2     CAX_2       2     5000  115.342793\n",
       "3     CAX_3       3     5000  118.859190\n",
       "4     CAX_4       4     5000  127.735587"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([PosixPath('../data/train_images/cropped_512/test/well_5540_crop_2.png'),\n",
       "       PosixPath('../data/train_images/cropped_512/test/well_5927_crop_6.png'),\n",
       "       PosixPath('../data/train_images/cropped_512/test/well_5883_crop_5.png'),\n",
       "       PosixPath('../data/train_images/cropped_512/test/well_5316_crop_1.png'), ...,\n",
       "       PosixPath('../data/train_images/cropped_512/test/well_5338_crop_7.png'),\n",
       "       PosixPath('../data/train_images/cropped_512/test/well_6255_crop_6.png'),\n",
       "       PosixPath('../data/train_images/cropped_512/test/well_5127_crop_5.png'),\n",
       "       PosixPath('../data/train_images/cropped_512/test/well_6308_crop_7.png')], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    images 2200 x 512\\n    2048 covered in first 4 crops\\n\\n    def crop_n(img, crop_start):\\n        #(left, top, right, bottom)\\n        img_width, img_height = img.size\\n        \\n        if crop_start<4:\\n            cs = crop_start*(img_height)\\n        elif crop_start==7:\\n            cs = img_width-img_height\\n        else:\\n            cs = int(((crop_start-4)+0.5)*(img_height))\\n        crop=((cs),0,(cs + img_height), img_height)\\n        return img.crop(crop)\\n        \\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cropping method - now need to recombine\n",
    "'''\n",
    "    images 2200 x 512\n",
    "    2048 covered in first 4 crops\n",
    "\n",
    "    def crop_n(img, crop_start):\n",
    "        #(left, top, right, bottom)\n",
    "        img_width, img_height = img.size\n",
    "        \n",
    "        if crop_start<4:\n",
    "            cs = crop_start*(img_height)\n",
    "        elif crop_start==7:\n",
    "            cs = img_width-img_height\n",
    "        else:\n",
    "            cs = int(((crop_start-4)+0.5)*(img_height))\n",
    "        crop=((cs),0,(cs + img_height), img_height)\n",
    "        return img.crop(crop)\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_well_list(test_data):\n",
    "    ids=[]\n",
    "    for f in test_data:\n",
    "        id=f.name.split('_')[1]\n",
    "        ids.append(id)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=test_data.items.tolist()\n",
    "well_ds=get_well_list(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(well_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coerce the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we take each image and take the mode (most common prediction) of y for each x to get the overall facies prediction at that x (where x = depth, y = facies pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('training_data', 447579160),\n",
       " ('test_df', 201289050),\n",
       " ('all_wells_df', 279050),\n",
       " ('npa', 262256),\n",
       " ('well_ds', 140592),\n",
       " ('v', 128072),\n",
       " ('wells', 32096),\n",
       " ('fastai_types', 2288),\n",
       " ('DataLoader', 1472),\n",
       " ('EmptyLabelList', 1472),\n",
       " ('ImageDataBunch', 1472),\n",
       " ('Learner', 1472),\n",
       " ('SegmentationItemList', 1472),\n",
       " ('SegmentationLabelList', 1472),\n",
       " ('progress_bar', 1472),\n",
       " ('FlattenedLoss', 1192),\n",
       " ('LabelList', 1192),\n",
       " ('OptimWrapper', 1192),\n",
       " ('Recorder', 1192),\n",
       " ('Series', 1192),\n",
       " ('TfmAffine', 1192),\n",
       " ('TfmCoord', 1192),\n",
       " ('TfmCrop', 1192),\n",
       " ('TfmLighting', 1192),\n",
       " ('AUROC', 1064),\n",
       " ('AccumulateScheduler', 1064),\n",
       " ('AdaptiveConcatPool2d', 1064),\n",
       " ('AffineMatrix', 1064),\n",
       " ('AverageMetric', 1064),\n",
       " ('BatchNorm1dFlat', 1064),\n",
       " ('BatchSampler', 1064),\n",
       " ('BnFreeze', 1064),\n",
       " ('Callback', 1064),\n",
       " ('CallbackHandler', 1064),\n",
       " ('Category', 1064),\n",
       " ('CategoryList', 1064),\n",
       " ('CategoryProcessor', 1064),\n",
       " ('ClassificationInterpretation', 1064),\n",
       " ('Config', 1064),\n",
       " ('ConfusionMatrix', 1064),\n",
       " ('Counter', 1064),\n",
       " ('DataBunch', 1064),\n",
       " ('DataFrame', 1064),\n",
       " ('Dataset', 1064),\n",
       " ('DatasetType', 1064),\n",
       " ('Debugger', 1064),\n",
       " ('DeviceDataLoader', 1064),\n",
       " ('DistributedDataParallel', 1064),\n",
       " ('EmptyLabel', 1064),\n",
       " ('Enum', 1064),\n",
       " ('ExpRMSPE', 1064),\n",
       " ('ExplainedVariance', 1064),\n",
       " ('FBeta', 1064),\n",
       " ('Flatten', 1064),\n",
       " ('FloatItem', 1064),\n",
       " ('FloatList', 1064),\n",
       " ('FlowField', 1064),\n",
       " ('GradientClipping', 1064),\n",
       " ('Image', 1064),\n",
       " ('ImageBBox', 1064),\n",
       " ('ImageImageList', 1064),\n",
       " ('ImageList', 1064),\n",
       " ('ImagePoints', 1064),\n",
       " ('ImageSegment', 1064),\n",
       " ('InitVar', 1064),\n",
       " ('IntEnum', 1064),\n",
       " ('Interpretation', 1064),\n",
       " ('ItemBase', 1064),\n",
       " ('ItemList', 1064),\n",
       " ('ItemLists', 1064),\n",
       " ('KappaScore', 1064),\n",
       " ('LabelLists', 1064),\n",
       " ('LabelSmoothingCrossEntropy', 1064),\n",
       " ('Lambda', 1064),\n",
       " ('LearnerCallback', 1064),\n",
       " ('LogitTensorImage', 1064),\n",
       " ('MasterBar', 1064),\n",
       " ('MatthewsCorreff', 1064),\n",
       " ('MergeLayer', 1064),\n",
       " ('MixedItem', 1064),\n",
       " ('MixedItemList', 1064),\n",
       " ('MixedProcessor', 1064),\n",
       " ('ModelOnCPU', 1064),\n",
       " ('Module', 1064),\n",
       " ('MultiCategory', 1064),\n",
       " ('MultiCategoryList', 1064),\n",
       " ('MultiCategoryProcessor', 1064),\n",
       " ('MultiLabelClassificationInterpretation', 1064),\n",
       " ('MultiLabelFbeta', 1064),\n",
       " ('NoneReduceOnCPU', 1064),\n",
       " ('NoopLoss', 1064),\n",
       " ('NormType', 1064),\n",
       " ('ObjectCategoryList', 1064),\n",
       " ('ObjectItemList', 1064),\n",
       " ('ParameterModule', 1064),\n",
       " ('PartialLayer', 1064),\n",
       " ('Patch', 1064),\n",
       " ('Perplexity', 1064),\n",
       " ('PixelShuffle_ICNR', 1064),\n",
       " ('PointsItemList', 1064),\n",
       " ('PointsLabelList', 1064),\n",
       " ('PooledSelfAttention2d', 1064),\n",
       " ('PrePostInitMeta', 1064),\n",
       " ('PreProcessor', 1064),\n",
       " ('Precision', 1064),\n",
       " ('PrettyString', 1064),\n",
       " ('ProcessPoolExecutor', 1064),\n",
       " ('ProgressBar', 1064),\n",
       " ('R2Score', 1064),\n",
       " ('RMSE', 1064),\n",
       " ('RandTransform', 1064),\n",
       " ('Recall', 1064),\n",
       " ('RecordOnCPU', 1064),\n",
       " ('ResizeBatch', 1064),\n",
       " ('ResizeMethod', 1064),\n",
       " ('Sampler', 1064),\n",
       " ('SaveModelCallback', 1064),\n",
       " ('Scheduler', 1064),\n",
       " ('SegmentationInterpretation', 1064),\n",
       " ('SegmentationProcessor', 1064),\n",
       " ('SelfAttention', 1064),\n",
       " ('SequentialEx', 1064),\n",
       " ('ShowGraph', 1064),\n",
       " ('SigmoidRange', 1064),\n",
       " ('SmoothenValue', 1064),\n",
       " ('Tensor', 1064),\n",
       " ('TensorDataset', 1064),\n",
       " ('TensorImage', 1064),\n",
       " ('ThreadPoolExecutor', 1064),\n",
       " ('Transform', 1064),\n",
       " ('TypeVar', 1064),\n",
       " ('URLs', 1064),\n",
       " ('View', 1064),\n",
       " ('WassersteinLoss', 1064),\n",
       " ('abstractproperty', 1064),\n",
       " ('master_bar', 1064),\n",
       " ('Integral', 896),\n",
       " ('Iterable', 896),\n",
       " ('Number', 896),\n",
       " ('Path', 896),\n",
       " ('TfmPixel', 896),\n",
       " ('BufferedWriter', 400),\n",
       " ('ByteTensor', 400),\n",
       " ('BytesIO', 400),\n",
       " ('DoubleTensor', 400),\n",
       " ('FloatTensor', 400),\n",
       " ('HalfTensor', 400),\n",
       " ('ImgLabel', 400),\n",
       " ('LongTensor', 400),\n",
       " ('NPArray', 400),\n",
       " ('NPArrayMask', 400),\n",
       " ('NPImage', 400),\n",
       " ('OrderedDict', 400),\n",
       " ('ShortTensor', 400),\n",
       " ('SimpleNamespace', 400),\n",
       " ('attrgetter', 400),\n",
       " ('defaultdict', 400),\n",
       " ('itemgetter', 400),\n",
       " ('partial', 400),\n",
       " ('name2id', 376),\n",
       " ('codes', 360),\n",
       " ('cos', 248),\n",
       " ('exp', 248),\n",
       " ('log', 248),\n",
       " ('sin', 248),\n",
       " ('tan', 248),\n",
       " ('tanh', 248),\n",
       " ('BCEFlat', 144),\n",
       " ('BCEWithLogitsFlat', 144),\n",
       " ('CrossEntropyFlat', 144),\n",
       " ('MSELossFlat', 144),\n",
       " ('NewType', 144),\n",
       " ('PoolFlatten', 144),\n",
       " ('Rank0Tensor', 144),\n",
       " ('abstractmethod', 144),\n",
       " ('acc_bgvoid', 144),\n",
       " ('accuracy', 144),\n",
       " ('accuracy_thresh', 144),\n",
       " ('add_metrics', 144),\n",
       " ('annealing_cos', 144),\n",
       " ('annealing_exp', 144),\n",
       " ('annealing_linear', 144),\n",
       " ('annealing_no', 144),\n",
       " ('annealing_poly', 144),\n",
       " ('apply_init', 144),\n",
       " ('apply_leaf', 144),\n",
       " ('arange_of', 144),\n",
       " ('arrays_split', 144),\n",
       " ('auc_roc_score', 144),\n",
       " ('batch_to_half', 144),\n",
       " ('batchnorm_2d', 144),\n",
       " ('bb2hw', 144),\n",
       " ('bb_pad_collate', 144),\n",
       " ('bn2float', 144),\n",
       " ('bn_drop_lin', 144),\n",
       " ('bunzip', 144),\n",
       " ('camel2snake', 144),\n",
       " ('channel_view', 144),\n",
       " ('children', 144),\n",
       " ('children_and_parameters', 144),\n",
       " ('chunks', 144),\n",
       " ('cnn_learner', 144),\n",
       " ('compose', 144),\n",
       " ('cond_init', 144),\n",
       " ('contextmanager', 144),\n",
       " ('conv2d', 144),\n",
       " ('conv2d_trans', 144),\n",
       " ('conv_layer', 144),\n",
       " ('create_body', 144),\n",
       " ('create_cnn', 144),\n",
       " ('create_cnn_model', 144),\n",
       " ('create_head', 144),\n",
       " ('data_collate', 144),\n",
       " ('dataclass', 144),\n",
       " ('datapath4file', 144),\n",
       " ('deepcopy', 144),\n",
       " ('denormalize', 144),\n",
       " ('df_names_to_idx', 144),\n",
       " ('dice', 144),\n",
       " ('display', 144),\n",
       " ('distrib_barrier', 144),\n",
       " ('doc', 144),\n",
       " ('download_data', 144),\n",
       " ('download_images', 144),\n",
       " ('download_url', 144),\n",
       " ('embedding', 144),\n",
       " ('error_rate', 144),\n",
       " ('even_mults', 144),\n",
       " ('exp_rmspe', 144),\n",
       " ('explained_variance', 144),\n",
       " ('extract_kwargs', 144),\n",
       " ('fbeta', 144),\n",
       " ('field', 144),\n",
       " ('find_classes', 144),\n",
       " ('first_el', 144),\n",
       " ('first_layer', 144),\n",
       " ('fit', 144),\n",
       " ('fit_fc', 144),\n",
       " ('fit_one_cycle', 144),\n",
       " ('flatten_check', 144),\n",
       " ('flatten_model', 144),\n",
       " ('float_or_x', 144),\n",
       " ('foreground_acc', 144),\n",
       " ('func_args', 144),\n",
       " ('get_annotations', 144),\n",
       " ('get_files', 144),\n",
       " ('get_image_files', 144),\n",
       " ('get_model', 144),\n",
       " ('get_param_groups', 144),\n",
       " ('get_preds', 144),\n",
       " ('get_tmp_file', 144),\n",
       " ('get_transforms', 144),\n",
       " ('get_well_list', 144),\n",
       " ('grab_idx', 144),\n",
       " ('has_arg', 144),\n",
       " ('has_params', 144),\n",
       " ('have_min_pkg_version', 144),\n",
       " ('icnr', 144),\n",
       " ('idx_dict', 144),\n",
       " ('ifnone', 144),\n",
       " ('image2np', 144),\n",
       " ('in_channels', 144),\n",
       " ('index_row', 144),\n",
       " ('init_default', 144),\n",
       " ('is1d', 144),\n",
       " ('is_dict', 144),\n",
       " ('is_listy', 144),\n",
       " ('is_pathlike', 144),\n",
       " ('is_pool_type', 144),\n",
       " ('is_tuple', 144),\n",
       " ('join_path', 144),\n",
       " ('join_paths', 144),\n",
       " ('last_layer', 144),\n",
       " ('listify', 144),\n",
       " ('load_data', 144),\n",
       " ('load_learner', 144),\n",
       " ('loadtxt_str', 144),\n",
       " ('log_uniform', 144),\n",
       " ('logit', 144),\n",
       " ('logit_', 144),\n",
       " ('loss_batch', 144),\n",
       " ('lr_find', 144),\n",
       " ('mae', 144),\n",
       " ('mask2rle', 144),\n",
       " ('mean_absolute_error', 144),\n",
       " ('mean_squared_error', 144),\n",
       " ('mean_squared_logarithmic_error', 144),\n",
       " ('mixup', 144),\n",
       " ('mode', 144),\n",
       " ('model2half', 144),\n",
       " ('model_type', 144),\n",
       " ('mse', 144),\n",
       " ('msle', 144),\n",
       " ('namedtuple', 144),\n",
       " ('noop', 144),\n",
       " ('normalize', 144),\n",
       " ('normalize_funcs', 144),\n",
       " ('np2model_tensor', 144),\n",
       " ('np_address', 144),\n",
       " ('np_func', 144),\n",
       " ('num_children', 144),\n",
       " ('num_cpus', 144),\n",
       " ('num_distrib', 144),\n",
       " ('one_cycle_scheduler', 144),\n",
       " ('one_hot', 144),\n",
       " ('one_param', 144),\n",
       " ('open_image', 144),\n",
       " ('open_mask', 144),\n",
       " ('open_mask_rle', 144),\n",
       " ('parallel', 144),\n",
       " ('partition', 144),\n",
       " ('partition_by_cores', 144),\n",
       " ('pil2tensor', 144),\n",
       " ('plot_flat', 144),\n",
       " ('plot_multi', 144),\n",
       " ('r2_score', 144),\n",
       " ('rand_bool', 144),\n",
       " ('rand_crop', 144),\n",
       " ('rand_pad', 144),\n",
       " ('rand_resize_crop', 144),\n",
       " ('rand_zoom', 144),\n",
       " ('random_split', 144),\n",
       " ('range_children', 144),\n",
       " ('range_of', 144),\n",
       " ('rank_distrib', 144),\n",
       " ('recurse', 144),\n",
       " ('recurse_eq', 144),\n",
       " ('relu', 144),\n",
       " ('remove_module_load', 144),\n",
       " ('requires_grad', 144),\n",
       " ('res_block', 144),\n",
       " ('resize_to', 144),\n",
       " ('rle2mask', 144),\n",
       " ('rle_decode', 144),\n",
       " ('rle_encode', 144),\n",
       " ('rmse', 144),\n",
       " ('roc_curve', 144),\n",
       " ('root_mean_squared_error', 144),\n",
       " ('save_texts', 144),\n",
       " ('scale_flow', 144),\n",
       " ('series2cat', 144),\n",
       " ('set_all_seed', 144),\n",
       " ('set_bn_eval', 144),\n",
       " ('set_trace', 144),\n",
       " ('show_all', 144),\n",
       " ('show_image', 144),\n",
       " ('show_multi', 144),\n",
       " ('show_some', 144),\n",
       " ('sigmoid_range', 144),\n",
       " ('simple_cnn', 144),\n",
       " ('spectral_norm', 144),\n",
       " ('split_kwargs_by_func', 144),\n",
       " ('split_model', 144),\n",
       " ('split_model_idx', 144),\n",
       " ('split_no_wd_params', 144),\n",
       " ('subplots', 144),\n",
       " ('tensor', 144),\n",
       " ('text2html_table', 144),\n",
       " ('tis2hw', 144),\n",
       " ('to_cpu', 144),\n",
       " ('to_data', 144),\n",
       " ('to_detach', 144),\n",
       " ('to_device', 144),\n",
       " ('to_float', 144),\n",
       " ('to_fp16', 144),\n",
       " ('to_fp32', 144),\n",
       " ('to_half', 144),\n",
       " ('to_int', 144),\n",
       " ('to_np', 144),\n",
       " ('top_k_accuracy', 144),\n",
       " ('train_epoch', 144),\n",
       " ('trainable_params', 144),\n",
       " ('trange_of', 144),\n",
       " ('trunc_normal_', 144),\n",
       " ('try_import', 144),\n",
       " ('try_int', 144),\n",
       " ('try_save', 144),\n",
       " ('unet_learner', 144),\n",
       " ('uniform', 144),\n",
       " ('uniform_int', 144),\n",
       " ('uniqueify', 144),\n",
       " ('untar_data', 144),\n",
       " ('url2name', 144),\n",
       " ('url2path', 144),\n",
       " ('validate', 144),\n",
       " ('verify_images', 144),\n",
       " ('weight_norm', 144),\n",
       " ('working_directory', 144),\n",
       " ('zoom_crop', 144),\n",
       " ('data_dir', 120),\n",
       " ('file_test', 120),\n",
       " ('filename', 120),\n",
       " ('preds_path', 120),\n",
       " ('test_img', 120),\n",
       " ('train_images', 120),\n",
       " ('train_img', 120),\n",
       " ('train_mask', 120),\n",
       " ('train_path', 120),\n",
       " ('bias_types', 112),\n",
       " ('AnyStr', 104),\n",
       " ('AdamW', 96),\n",
       " ('INFERENCE_MODEL', 89),\n",
       " ('F', 88),\n",
       " ('callbacks', 88),\n",
       " ('models', 88),\n",
       " ('nn', 88),\n",
       " ('no_wd_types', 88),\n",
       " ('np', 88),\n",
       " ('optim', 88),\n",
       " ('patches', 88),\n",
       " ('patheffects', 88),\n",
       " ('pd', 88),\n",
       " ('pil_image', 88),\n",
       " ('plt', 88),\n",
       " ('vision', 88),\n",
       " ('Any', 80),\n",
       " ('Optional', 80),\n",
       " ('Union', 80),\n",
       " ('as_tensor', 80),\n",
       " ('bn_types', 80),\n",
       " ('labels', 80),\n",
       " ('preds', 80),\n",
       " ('reduce', 80),\n",
       " ('warn', 80),\n",
       " ('cifar_stats', 72),\n",
       " ('imagenet_stats', 72),\n",
       " ('mnist_stats', 72),\n",
       " ('AffineFunc', 64),\n",
       " ('AnnealFunc', 64),\n",
       " ('ArgStar', 64),\n",
       " ('BatchSamples', 64),\n",
       " ('BoolOrTensor', 64),\n",
       " ('Callable', 64),\n",
       " ('CallbackList', 64),\n",
       " ('Collection', 64),\n",
       " ('CoordFunc', 64),\n",
       " ('DataFrameOrChunks', 64),\n",
       " ('Dict', 64),\n",
       " ('FilePathList', 64),\n",
       " ('FloatOrTensor', 64),\n",
       " ('Floats', 64),\n",
       " ('Hashable', 64),\n",
       " ('HookFunc', 64),\n",
       " ('ImgLabels', 64),\n",
       " ('IntOrTensor', 64),\n",
       " ('IntsOrStrs', 64),\n",
       " ('ItemsList', 64),\n",
       " ('Iterator', 64),\n",
       " ('KWArgs', 64),\n",
       " ('KeyFunc', 64),\n",
       " ('LambdaFunc', 64),\n",
       " ('LayerFunc', 64),\n",
       " ('LightingFunc', 64),\n",
       " ('List', 64),\n",
       " ('ListOrItem', 64),\n",
       " ('ListRules', 64),\n",
       " ('ListSizes', 64),\n",
       " ('LossFunction', 64),\n",
       " ('Mapping', 64),\n",
       " ('MetricFunc', 64),\n",
       " ('MetricFuncList', 64),\n",
       " ('MetricsList', 64),\n",
       " ('ModuleList', 64),\n",
       " ('NPArrayList', 64),\n",
       " ('NPArrayableList', 64),\n",
       " ('OptDataFrame', 64),\n",
       " ('OptListOrItem', 64),\n",
       " ('OptLossFunc', 64),\n",
       " ('OptMetrics', 64),\n",
       " ('OptOptimizer', 64),\n",
       " ('OptRange', 64),\n",
       " ('OptSplitFunc', 64),\n",
       " ('OptStats', 64),\n",
       " ('OptStrList', 64),\n",
       " ('OptStrTuple', 64),\n",
       " ('PBar', 64),\n",
       " ('ParamList', 64),\n",
       " ('PathLikeOrBinaryStream', 64),\n",
       " ('PathOrStr', 64),\n",
       " ('PixelFunc', 64),\n",
       " ('Point', 64),\n",
       " ('Points', 64),\n",
       " ('Sequence', 64),\n",
       " ('Sizes', 64),\n",
       " ('SplitArrayList', 64),\n",
       " ('SplitFunc', 64),\n",
       " ('SplitFuncOrIdxList', 64),\n",
       " ('StartOptEnd', 64),\n",
       " ('StrList', 64),\n",
       " ('TensorImageSize', 64),\n",
       " ('TensorOrNumList', 64),\n",
       " ('TensorOrNumber', 64),\n",
       " ('Tensors', 64),\n",
       " ('TfmList', 64),\n",
       " ('Tokens', 64),\n",
       " ('Tuple', 64),\n",
       " ('VAL_FILE', 64),\n",
       " ('Weights', 64),\n",
       " ('brightness', 64),\n",
       " ('contrast', 64),\n",
       " ('crop', 64),\n",
       " ('crop_pad', 64),\n",
       " ('cutout', 64),\n",
       " ('dihedral', 64),\n",
       " ('dihedral_affine', 64),\n",
       " ('flip_affine', 64),\n",
       " ('flip_lr', 64),\n",
       " ('img', 64),\n",
       " ('jitter', 64),\n",
       " ('learn', 64),\n",
       " ('pad', 64),\n",
       " ('perspective_warp', 64),\n",
       " ('rgb_randomize', 64),\n",
       " ('rotate', 64),\n",
       " ('skew', 64),\n",
       " ('squish', 64),\n",
       " ('symmetric_warp', 64),\n",
       " ('test_data', 64),\n",
       " ('tilt', 64),\n",
       " ('zoom', 64),\n",
       " ('DATE', 57),\n",
       " ('UID', 57),\n",
       " ('defaults', 56),\n",
       " ('NB', 54),\n",
       " ('SUBSET_LEN', 28),\n",
       " ('TGT_HEIGHT_FULL', 28),\n",
       " ('TGT_HEIGHT_MEDIUM', 28),\n",
       " ('TGT_HEIGHT_SMALL', 28),\n",
       " ('SUBSET_DATA', 24),\n",
       " ('void_code', 24)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=None\n",
    "preds = None\n",
    "training_data = None\n",
    "test_df = None\n",
    "all_wells_df = None\n",
    "npa = None\n",
    "well_ds = None\n",
    "v = None\n",
    "wells = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "pid = os.getpid()\n",
    "py = psutil.Process(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mode_on_cols(labels,image_files):\n",
    "    print(f'len(data): {len(image_files)}, labels.shape[0]: {labels.shape[0]}')\n",
    "    frames=[]\n",
    "    for i, f in enumerate(image_files):\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "        if i==0:\n",
    "           print(f'starting memory use: {memoryUse}') \n",
    "        elif memoryUse>86.0:\n",
    "            print(f'killing process at image {i}, memory use: {memoryUse}')\n",
    "            break\n",
    "        name=f.name.split('.png')[0]\n",
    "        well_id=name.split('_crop_')[0]\n",
    "        crop_idx=name.split('_crop_')[1]\n",
    "        row_ids=range(len(labels[i]))\n",
    "        n=labels[i]\n",
    "        m_mask = n != 0  \n",
    "        new_m = np.where(m_mask, n, np.nan)\n",
    "        m=mode(new_m, axis=0)\n",
    "        r=m[0].flatten().astype(int)\n",
    "        well_col=[well_id] * len(n)\n",
    "        crop_col=[crop_idx] * len(n)\n",
    "        tdf = pd.DataFrame({'row_id': row_ids, 'facies': r,\n",
    "                            'well_id': well_col, 'crop_idx': crop_col})\n",
    "        frames.append(tdf)\n",
    "    memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "    print(f'end memory use: {memoryUse}')\n",
    "    df = pd.concat(frames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this in parts so dont use all memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data): 16000, labels.shape[0]: 16000\n",
      "starting memory use: 35.984317779541016\n",
      "end memory use: 35.984615325927734\n"
     ]
    }
   ],
   "source": [
    "#df=calc_mode_on_cols(labels[:4000],test_data.items[:4000])\n",
    "df=calc_mode_on_cols(labels,test_data.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>facies</th>\n",
       "      <th>well_id</th>\n",
       "      <th>crop_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5540</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  facies    well_id crop_idx\n",
       "0       0       2  well_5540        2\n",
       "1       1       2  well_5540        2\n",
       "2       2       2  well_5540        2\n",
       "3       3       2  well_5540        2\n",
       "4       4       2  well_5540        2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02_10_1-be4a9fe2_rn34_256-s2-r0-20191222'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFERENCE_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(preds_path/f'{INFERENCE_MODEL}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>facies</th>\n",
       "      <th>well_id</th>\n",
       "      <th>crop_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>2</td>\n",
       "      <td>well_6308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>2</td>\n",
       "      <td>well_6308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>2</td>\n",
       "      <td>well_6308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>2</td>\n",
       "      <td>well_6308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>2</td>\n",
       "      <td>well_6308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  facies    well_id crop_idx\n",
       "251     251       2  well_6308        7\n",
       "252     252       2  well_6308        7\n",
       "253     253       2  well_6308        7\n",
       "254     254       2  well_6308        7\n",
       "255     255       2  well_6308        7"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['well_id', 'row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>facies</th>\n",
       "      <th>well_id</th>\n",
       "      <th>crop_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>well_5000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>well_5000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  facies    well_id crop_idx\n",
       "0       0       2  well_5000        7\n",
       "0       0       2  well_5000        6\n",
       "0       0       2  well_5000        0\n",
       "0       0       2  well_5000        5\n",
       "0       0       4  well_5000        3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
