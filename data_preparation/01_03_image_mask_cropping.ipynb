{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentaion with masked facies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from numbers import Integral\n",
    "from random import uniform\n",
    "from PIL import Image as pil_image\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.vision import Image\n",
    "from fastai.vision.transform import _minus_epsilon\n",
    "from fastai.vision.data import SegmentationProcessor\n",
    "from mask_functions import *\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from IPython.display import display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.60.dev0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_DATA=False\n",
    "SUBSET_LEN=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_height = 256\n",
    "data_dir = Path('data')\n",
    "train_images = data_dir/'train_images'\n",
    "test_img = train_images/'mask_fill/test'\n",
    "\n",
    "\n",
    "train_path = train_images/'mask_fill/train'\n",
    "train_mask = train_path/'masks'\n",
    "train_img = train_path/'images'\n",
    "\n",
    "cropped_base=train_images/'cropped'\n",
    "cropped_base.mkdir(exist_ok=True) \n",
    "cropped_base = cropped_base/'mask_fill'\n",
    "cropped_base.mkdir(exist_ok=True) \n",
    "cropped_train = cropped_base/'train'\n",
    "cropped_train.mkdir(exist_ok=True) \n",
    "\n",
    "cropped_train_mask = cropped_train/'masks'\n",
    "cropped_train_mask.mkdir(exist_ok=True) \n",
    "\n",
    "cropped_train_img = cropped_train/'images'\n",
    "cropped_train_img.mkdir(exist_ok=True) \n",
    "\n",
    "cropped_test = cropped_base/'test'\n",
    "cropped_test.mkdir(exist_ok=True) \n",
    "cropped_test_img=cropped_test/'cropped'\n",
    "cropped_test_img.mkdir(exist_ok=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/CAX_LogFacies_Train_File.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(filename)\n",
    "training_data.head()\n",
    "training_data['well_file']='well_'+training_data['well_id'].astype(str)+'.png'\n",
    "wells=training_data['well_file'].unique()\n",
    "all_wells_df=pd.DataFrame(wells)\n",
    "all_wells_df.head()\n",
    "    \n",
    "df_val = all_wells_df.sample(frac=0.2)\n",
    "idx=df_val.index\n",
    "df_trn=all_wells_df[~all_wells_df.index.isin(idx)]\n",
    "assert len(df_val)+len(df_trn)==len(all_wells_df)\n",
    "df_val.to_csv(train_path/'val_20pct.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3492</td>\n",
       "      <td>well_3492.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2515</td>\n",
       "      <td>well_2515.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2928</td>\n",
       "      <td>well_2928.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>well_143.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>well_15.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "3492  well_3492.png\n",
       "2515  well_2515.png\n",
       "2928  well_2928.png\n",
       "143    well_143.png\n",
       "15      well_15.png"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(train_images/'mask_fill/train/val_20pct.csv', names=[\"well_id\"])\n",
    "ids=range(0,SUBSET_LEN)\n",
    "well_names=[]\n",
    "for i in ids:\n",
    "    well_names.append('well_'+str(i)+'.png')\n",
    "#df_sub_val=df_val.loc[df_val['well_id'].isin(well_names)]\n",
    "#df_sub_val.to_csv(train_sub_path/'val_sub_20pct.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_names = get_image_files(train_img)\n",
    "len(train_img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/train_images/mask_fill/train/images/well_2640.png'),\n",
       " PosixPath('data/train_images/mask_fill/train/images/well_2552.png'),\n",
       " PosixPath('data/train_images/mask_fill/train/images/well_1321.png')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/train_images/mask_fill/train/masks/well_2640.png'),\n",
       " PosixPath('data/train_images/mask_fill/train/masks/well_2552.png'),\n",
       " PosixPath('data/train_images/mask_fill/train/masks/well_1321.png')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask_names = get_image_files(train_mask)\n",
    "train_mask_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/train_images/mask_fill/test/well_6076_GR.png'),\n",
       " PosixPath('data/train_images/mask_fill/test/well_5383_GR.png'),\n",
       " PosixPath('data/train_images/mask_fill/test/well_5135_GR.png')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_names = get_image_files(test_img)\n",
    "test_img_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_img_names = get_image_files(cropped_train_img)\n",
    "c_train_mask_names = get_image_files(cropped_train_mask)\n",
    "c_test_img_names = get_image_files(cropped_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize all images to square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to(f, outpath):\n",
    "    '''using open CV to resize as this allows exact dims to be used'''\n",
    "    pil_im=pil_image.open(f)\n",
    "    img=np.array(pil_im)\n",
    "    opencvImage = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    resized = cv2.resize(img, size, interpolation = cv2.INTER_LANCZOS4) \n",
    "    outimg = pil_image.fromarray(resized, \"RGB\" )\n",
    "    out_file=outpath/f'{f.name}'\n",
    "    outimg.save(out_file)\n",
    "    outimg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_all(size, fnames, mnames):\n",
    "    pma=path_lbl/f'{size[0]}'\n",
    "    os.makedirs(pma, exist_ok=True)\n",
    "    pim=path_img/f'{size[0]}'\n",
    "    os.makedirs(pim, exist_ok=True)\n",
    "    for f in fnames:\n",
    "        resize_to(f, pim)\n",
    "    for f in mnames:\n",
    "        resize_to(f, pma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize_all((tgt_height,tgt_height), fnames, lbl_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_masks():\n",
    "    img = img.resize((new_width, new_height), Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_n(img, crop_start):\n",
    "    #(left, top, right, bottom)\n",
    "    img_width, img_height = img.size\n",
    "    if crop_start<4:\n",
    "        cs = crop_start*(img_height)\n",
    "    else:\n",
    "        cs = int(((crop_start-4)+0.5)*(img_height))\n",
    "    #print(f'w {img_width}, h {img_height}, crop_start: {crop_start}, cs: {cs}')\n",
    "    crop=((cs),0,(cs + img_height), img_height)\n",
    "    #print(crop)\n",
    "    return img.crop(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_n_save(im, out_pth):\n",
    "    x=pil_image.open(im)\n",
    "    im_name=im.name.split('.png')[0]\n",
    "    for n in range(7):\n",
    "        c=crop_n(x, n)\n",
    "        c.save(out_pth/f'{im_name}_crop_{n}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in train_img_names:\n",
    "    crop_n_save(im, cropped_train_img)\n",
    "    \n",
    "for mask in train_mask_names:\n",
    "    crop_n_save(mask, cropped_train_mask)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in test_img_names:\n",
    "    crop_n_save(im, cropped_test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = [open_image(cropped_train_img/f'well_{i}_crop_5.png') for i in range(6)]\n",
    "im_masks = [open_image(cropped_train_mask/f'well_{i}_crop_5.png') for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ims[0].show(figsize=(18,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAFKUlEQVR4nO3d3XKbOgBGUSDN+z9xwrk449Z1Hcyf0Cd5rZnOtE3jgGFbCIM7zvM8AHmm2gsAPCdOCCVOCCVOCCVOCPVr6YvjODqVC4XN8zw++3sjJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Ra/FBp/jdNf17Dvr+/Ky4J78TICaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHECaHcMsbl3u0WvNv6bl1XIycUdP9CtPl7T1wO4ETihFDipHnTNB06fEzV3xrxtnoLtK+1gY6IE0KJk6rSDkVv89eE5aq/BHCin6JKCW6Ltpb2Ai1uRP72uP3u/3zltj36s+yFd0RJku6urf0psHe4hpP9El+Y85bogKUnuOSTn7hh+dnjSZ/U7Ze5VAWdPadc2sBn/azUnYeymj+s3bLjtnQy4PFxpmnq9tC8xC1ke2/TWvO4V20HL8kBnCHO9ezw96ptZY/YyNz1Pb3aNiVeYO0NcNCeKNd8T+yccxzHYRiGYZ7n37+/mee5+M8/MrdY88TvObPc87zzmTPmjYc+iWDFNnpcti3b/uVo/PKRKriP8THMK/10qOLwc7+1O+/aq3p63hb9rtkLhy+tOvDWSc871FE9P39b56VtruVJamzkVnes2mqdMa2p/zVc4R02dA+WLmjvUd9rt8KRV+Ledw7qitu7ap4AgiSLcRoZoB71XSD1+l+y2RMuIrpMydsld8mgAUWvtS72yAWN4+jEEd1rMs4bgdKzpuNsTfL8hjwv9xY7FNRRpTxzRnjt8jhTbgeDdE0fs4qbnjUdJ/RMnBBKnBBKnBCqepxO6sBz1eMcBoHCMxFxAv8SJ4QSJ4SK+e8YzDvhb0ZOCCVOCCVOCCVOCCVOCCVOCHVpnN4ugfWMnBCqWJw+xAuOKRKnKOE4h7UQSpwQSpwQSpwQ6rI4nSSCbS6JU5iwncNaCCVOCCVOCCVOCHVqnE78wHlOi/MWpkDhHA5rIZQ4IZQ4IZQ4IVTxOJ0ggn0Oxyk+KONQnN4+gXLMOSGUOCGUOCGUOCGUOCGUOCGUOCGUOCGUON/Ix8fH718/fZ0c4mQYhj9hPgt0KWjKESeLtkQp4HOJk1MsjbzsI04ItTtOd6JAWbviFCaU57D2jZWaH5p3nkOcHVt6X/PoCRzvmZYnzs4kvSeZshytEmenHsOoFYpA9/tVewE4x5EI1n7v7d99fX3t/lmsZ+TswNWjk9HwGuJsUNK8knLE2Zj7KAXaN3FymBeJMsTZkKuvzBJdXeJsnKt8+iVO/iHMDOKEUOKkmGmahmmyi+3lmaOI+yg/Pz8rLkm7xAmhNsfpRmu4hpETQokTQi3eMjbP81XLATwwckKoTXE6GQTXWR2nMOFaDmsh1KrPEDJqctTtKiGfP7SekRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCibMRLqF8P+KEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOKEUOM8z7WXAXjCyAmhxAmhxAmhxAmhxAmhxAmh/gO9qEMWWVuZ8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_masks[0].show(figsize=(18,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/ssd_1TB/Data/comps/crowdai/gamma_log_facies/train_images/cropped/mask_fill/test/cropped/well_5000_crop_5.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-85260cd82613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_test_img\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'well_{i}_crop_5.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-85260cd82613>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_test_img\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34mf'well_{i}_crop_5.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/963GB/Data/Python/Courses/fastai/fastai/fastai/vision/image.py\u001b[0m in \u001b[0;36mopen_image\u001b[0;34m(fn, div, convert_mode, cls, after_open)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# EXIF warning from TiffPlugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mafter_open\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafter_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai-dev/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/ssd_1TB/Data/comps/crowdai/gamma_log_facies/train_images/cropped/mask_fill/test/cropped/well_5000_crop_5.png'"
     ]
    }
   ],
   "source": [
    "imt = [open_image(cropped_test_img/f'well_{i}_crop_5.png') for i in range(5000, 5005)]\n",
    "imt[0].show(figsize=(18,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
